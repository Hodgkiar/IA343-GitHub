{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_691262928f3081918bbcf988640b104b\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-WwLvdWg9ZVKYd3hAKPfr7Q\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text.json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-WwLvdWg9ZVKYd3hAKPfr7Q\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1f1\n",
      " Relevant score: 0.6029813181076801\n",
      "Learning Plans. Use coupon code ùêíùêèùêãùüëùüé at checkout.üéØ\\n\\nJoin Now üëâ https://t.co/LS2JuCrVmz\\n\\n#AI #Ce\n",
      " Relevant score: 0.5984074448147717\n",
      "Create stunning, cinematic videos from a prompt‚Äînow with audio, physics, and cameos. One prompt = en\n",
      " Relevant score: 0.5911156596667607\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1d1\n",
      " Relevant score: 0.5622353955032359\n",
      "ü§§ AI is making cinematic food commercials in minutes. The sizzling patty, the dripping cheese... no \n",
      " Relevant score: 0.551242779477055\n"
     ]
    }
   ],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e96e622-9b8c-47d5-9a4a-3c3e6315b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of 2023, generative AI continues to advance rapidly, with several key developments:\n",
       "\n",
       "1. **Improved Language Models**: Newer language models have become more powerful, offering more nuanced and context-aware responses. These models are also being trained with a greater emphasis on ethical considerations and reducing biases.\n",
       "\n",
       "2. **Multimodal Capabilities**: AI systems are increasingly combining text, image, and audio data. This allows them to perform complex tasks such as generating detailed image descriptions, creating images from textual prompts, and producing synchronized audio-visual content.\n",
       "\n",
       "3. **Personalization**: Generative AI is being fine-tuned for individual users or specific applications, offering more personalized and context-relevant outputs.\n",
       "\n",
       "4. **Creative Applications**: Artists and designers are using generative AI for creative projects, from music composition to digital art and video game design. AI is also being used to generate deepfake content more responsibly and creatively.\n",
       "\n",
       "5. **AI in Research and Science**: Generative AI is playing a role in drug discovery, materials science, and other research fields by simulating complex processes and generating hypotheses for further investigation.\n",
       "\n",
       "6. **Regulation and Ethics**: There is a growing focus on establishing ethical guidelines and regulatory frameworks to manage the impact of generative AI on society, particularly concerning misinformation and IP rights.\n",
       "\n",
       "7. **Open Source Initiatives**: More open-source projects are emerging, allowing broader access to powerful generative models, fostering innovation, and community-based improvements.\n",
       "\n",
       "These advancements are expanding the applications and implications of generative AI across various domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It seems there are no specific details about the latest developments in generative AI in the uploaded files. However, I can provide a general overview based on current trends:\n",
       "\n",
       "1. **Advanced Language Models**: Models like GPT-4 have improved in understanding and generating human-like text, with better context awareness and coherence.\n",
       "\n",
       "2. **Multimodal Models**: These models can process and generate text, images, and other data types, allowing for more versatile applications.\n",
       "\n",
       "3. **Ethical AI**: There is a growing focus on making AI more ethical and reducing biases in AI-generated content.\n",
       "\n",
       "4. **AI in Creative Fields**: Generative AI is increasingly used in art, music, and content creation, enabling new forms of creativity.\n",
       "\n",
       "5. **Improved Efficiency**: New techniques are being developed to make generative models more efficient, reducing the computational resources required.\n",
       "\n",
       "If you have specific areas of interest, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive, in-depth overview (approx. 800 words) of the **latest developments in generative AI**, as of November 10, 2025. All major updates are accurately dated, clearly sourced, and professionally structured.\n",
       "\n",
       "##  Developments in Generative AI Models & Tools\n",
       "\n",
       "- **OpenAI‚Äôs GPT‚Äë5 is now broadly deployed** in ChatGPT, Microsoft Copilot, and available via API. Launched on August 7, 2025, this multimodal model set a new benchmark in reasoning and multimodal functionality ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai)).\n",
       "\n",
       "- **Google DeepMind‚Äôs Veo 3.1**, the latest version of its text-to-video model (part of the Veo series), was released on **October 15, 2025**, offering improved video generation capabilities with synchronized audio ([en.wikipedia.org](https://en.wikipedia.org/wiki/Veo_%28text-to-video_model%29?utm_source=openai)).\n",
       "\n",
       "- **Google‚Äôs ‚ÄúNano Banana‚Äù (Gemini 2.5 Flash Image)** continues driving viral popularity. Released August 26, 2025, it enables highly photorealistic 3D-figurine-style image editing and is embedded in Gemini app and Vertex AI. It achieved over 10 million first-time users and 200 million image edits shortly after launch ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai)).\n",
       "\n",
       "##  Major Strategic Partnerships & Infrastructure Advances\n",
       "\n",
       "- In a significant infrastructure expansion, **OpenAI and AWS signed a $38 billion strategic partnership on November 3, 2025**, granting OpenAI access to vast GPU resources and diversifying its compute infrastructure beyond Microsoft ([champaignmagazine.com](https://champaignmagazine.com/2025/11/09/ai-by-ai-weekly-top-5-november-3-9-2025/?utm_source=openai)).\n",
       "\n",
       "- On **November 5, 2025**, **Apple sealed a deal to integrate Google‚Äôs Gemini models into Siri**, paying approximately $1 billion annually. This marks a major shift in Apple‚Äôs virtual assistant strategy ([champaignmagazine.com](https://champaignmagazine.com/2025/11/09/ai-by-ai-weekly-top-5-november-3-9-2025/?utm_source=openai)).\n",
       "\n",
       "- On **November 6, 2025**, **Google unveiled ‚ÄúIronwood,‚Äù** its seventh-generation TPU chip, offering 4√ó performance gains over predecessor. This reinforces Google‚Äôs hardware independence and strengthens AI computing infrastructure ([champaignmagazine.com](https://champaignmagazine.com/2025/11/09/ai-by-ai-weekly-top-5-november-3-9-2025/?utm_source=openai)).\n",
       "\n",
       "##  Drug Discovery & Industry Applications\n",
       "\n",
       "- On **November 7, 2025**, **Insilico Medicine**, a clinical-stage AI-driven drug discovery company, showcased a new portfolio of cardiometabolic drug assets at BIO Europe 2025, emphasizing the role of generative AI in advancing pharmaceuticals ([eurekalert.org](https://www.eurekalert.org/news-releases/1105110?utm_source=openai)).\n",
       "\n",
       "- The **GENIUS project**, a large European collaboration, is advancing generative AI integration across the entire software development lifecycle, improving reliability and security in AI-assisted software engineering ([quantumzeitgeist.com](https://quantumzeitgeist.com/ai-genius-project-partners-advances-generative-integration-across-software/?utm_source=openai)).\n",
       "\n",
       "- **The Entertainer**, a UAE-based savings platform, partnered with **Zero&One** to introduce generative AI features within its app and cloud ecosystem, improving customer engagement and personalization ([consultancy-me.com](https://www.consultancy-me.com/news/12033/savings-platform-the-entertainer-selects-zeroone-as-cloud-and-gen-ai-partner?utm_source=openai)).\n",
       "\n",
       "##  Emerging AI Paradigms & Research Innovations\n",
       "\n",
       "- **Google Research introduced ‚ÄúNested Learning‚Äù** on November 7, 2025‚Äîa new continual learning paradigm framing models as nested optimization problems. It aims to address catastrophic forgetting by preserving performance on prior tasks while learning new ones ([research.google](https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/?utm_source=openai)).\n",
       "\n",
       "- **The CHI 2025 ‚ÄúTools for Thought‚Äù workshop (August 28, 2025)** explored how generative AI affects human cognition‚Äîcovering areas like memory, critical thinking, and metacognition‚Äîand proposed frameworks for designing AI tools that augment and protect human thought ([arxiv.org](https://arxiv.org/abs/2508.21036?utm_source=openai)).\n",
       "\n",
       "- **A recent information-theoretic framework** (published August 23, 2025) proposes introducing semantic-level metrics‚Äîlike semantic entropy and channel capacity‚Äîto support more meaningful, human-aligned multimedia communication via generative AI, beyond traditional syntactic measures ([arxiv.org](https://arxiv.org/abs/2508.17163?utm_source=openai)).\n",
       "\n",
       "- **CARING-AI**, a January 2025 research project, demonstrated context-aware AR instruction authored with generative AI avatars, enabling adaptive, location-aware learning through humanoid-avatar animations ([arxiv.org](https://arxiv.org/abs/2501.16557?utm_source=openai)).\n",
       "\n",
       "##  Safety, Regulation & Ethical Dynamics\n",
       "\n",
       "- **Tenable‚Äôs security researchers (today)** identified seven novel prompt injection methods that can exploit ChatGPT‚Äôs defaults to exfiltrate private data from chat histories‚Äîa serious emerging vulnerability ([csoonline.com](https://www.csoonline.com/article/4086965/researchers-trick-chatgpt-into-prompt-injecting-itself.html?utm_source=openai)).\n",
       "\n",
       "- **OpenAI‚Äôs ‚ÄúSora‚Äù video-gen AI app (2 days ago)** creates lifelike AI-generated videos quickly. Though powerful, it has sparked intense concern over safety and misinformation, particularly regarding its suitability for kids and potential for misuse ([abcnews.go.com](https://abcnews.go.com/GMA/Family/what-is-sora/story?id=127188940&utm_source=openai)).\n",
       "\n",
       "##  Summary\n",
       "\n",
       "The field of generative AI is advancing rapidly across multiple dimensions:\n",
       "\n",
       "- **Model innovation**: GPT‚Äë5, Gemini variants (including Nano Banana and Veo 3.1), and Alibaba‚Äôs Qwen series.\n",
       "- **Compute & infrastructure**: Massive partnerships (OpenAI‚ÄìAWS) and new hardware (Ironwood TPU).\n",
       "- **Cross-sector applications**: From smarter drug discovery to integrated AI in finance, media, and cloud apps.\n",
       "- **New learning paradigms**: Nested Learning and cognitive frameworks driving AI design.\n",
       "- **Ethical and safety vigilance**: Prompt injection vulnerabilities and AI-generated media ethics are more critical than ever.\n",
       "\n",
       "Let me know if you'd like a deeper dive into any specific area‚Äîe.g., GPT‚Äë5‚Äôs architecture, Veo‚Äôs capabilities, ethical frameworks, or AI integration in healthcare or AR."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive, in-depth overview (approx. 800 words) of the **latest developments in genera"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are several **different and recent developments** in the generative AI space, beyond what we've already covered:\n",
       "\n",
       "‚Ä¢ TIME launches the **TIME AI Agent** (Nov 10, 2025)  \n",
       "TIME and Scale AI have introduced the \"TIME AI Agent,\" a unified generative AI platform that enhances how readers interact with TIME's journalism. This system integrates language understanding, voice synthesis, translation, and search functions to offer dynamic engagement such as article summaries, audio reports, interactive exploration, and translations‚Äîall governed under TIME‚Äôs editorial standards for accuracy and transparency ([time.com](https://time.com/7332572/the-story-behind-the-time-ai-agent/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ OpenAI unveils **Aardvark**, a security-focused GPT-5‚Äìpowered agent (late October 2025)  \n",
       "OpenAI has rolled out ‚ÄúAardvark,‚Äù an agentic cybersecurity tool currently in private beta. Leveraging GPT‚Äë5, Aardvark autonomously scans code repositories for vulnerabilities‚Äîboasting about a 92% recall rate on seeded test cases‚Äîand has already contributed to ten officially tracked CVE-disclosed vulnerabilities ([aiwebbiz.com](https://aiwebbiz.com/blog/top-5-ai-news-of-the-week-november-2025/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ Explosive launch success for **Sora on Android**  \n",
       "OpenAI's video-generation app **Sora** premiered on Android on November 6, 2025, achieving roughly 470,000 downloads on its first day‚Äîsurpassing the iOS debut by a significant margin (approx. 360,000 downloads), representing a 327% increase ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **Google Gemini AI** expands with ‚ÄúDeep Research‚Äù and **Nano Banana 2** on the horizon  \n",
       "Gemini AI gains a new ‚ÄúDeep Research‚Äù capability, allowing it to leverage a user‚Äôs Gmail, Drive, and Chat content for context-aware and personalized responses ([medium.com](https://medium.com/%40CherryZhouTech/ai-news-november-1-7-2025-10-ai-advances-you-cant-miss-this-week-e2e86d331bd0?utm_source=openai)). Additionally, Google is reportedly preparing **Nano Banana 2**, an upgraded image generation model slated to launch soon, promising faster outputs, richer artistic styles, and built-in watermarking for transparency ([medium.com](https://medium.com/%40CherryZhouTech/ai-news-november-1-7-2025-10-ai-advances-you-cant-miss-this-week-e2e86d331bd0?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **Meta AI‚Äôs Vibes** expands to Europe  \n",
       "Meta‚Äôs AI-generated short video platform **Vibes**‚Äîwhich uses generative AI to create every video seen and made on the platform‚Äîhas now been launched in Europe via the Meta AI app, marking a major geographic expansion ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **DS‚ÄØSTAR**, beyond traditional data science  \n",
       "Google‚Äôs AI research team has introduced **DS‚ÄØSTAR** (‚ÄúData Science Agent via Iterative Planning and Verification‚Äù), a multi-agent AI framework that can translate ambiguous business problems into executable Python code, handling diverse data formats like CSV, JSON, Markdown, and plain text‚Äîwithout human supervision ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **HeyGen releases AI Video Translator with Realistic Localization**  \n",
       "HeyGen has debuted a next-generation AI video translator that enables foreign speakers to appear fluently speaking in other languages‚Äîcomplete with realistic expressions, lip movement, and tone‚Äîavailable via web, iOS, and API with free trial credits ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **Preview of Gemini 3 Pro** spotted on Vertex AI  \n",
       "A ‚Äúgemini-3-pro-preview-11-2025‚Äù model listing has appeared on Vertex AI, hinting at an imminent official launch. Expected to support a massive 1 million-token context window, it promises richer, longer-form interactions for developers and enterprises ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **Qualcomm announces AI200 and AI250 inference accelerators**  \n",
       "Qualcomm has revealed two AI inference accelerators‚ÄîAI200 (due 2026) and AI250 (due 2027)‚Äîpowered by its Hexagon NPUs. Built for data centers, they support advanced features like micro-tile inferencing, 64-bit addressing, GenAI model encryption, and near-memory compute architecture, along with compatibility with AI frameworks like PyTorch and ONNX ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai)).\n",
       "\n",
       "‚Ä¢ **Adobe unveils AI-powered creative tools across its ecosystem**  \n",
       "At Adobe MAX 2025, Adobe introduced a comprehensive suite of AI-powered enhancements across Express, Firefly, and Creative Cloud‚Äîincluding Firefly Image Model‚ÄØ5, end-to-end video generation, and integrations with tools like Photoshop, Premiere Pro, and even Google‚Äôs Nano Banana ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/adobe-launches-ai-audio-video-and-photo-tools-across-express-firefly-and-creative-cloud-brings-firefly-image-model-5-googles-nano-banana-and-more/articleshow/124876149.cms?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "### Summary of Key Trends\n",
       "\n",
       "- Generative AI is increasingly integrated into core tools across journalism, cybersecurity, navigation, and creative design.\n",
       "- Agentic AI‚Äîsystems that autonomously perform tasks‚Äîis advancing fast, seen in tools like Aardvark and DS‚ÄØSTAR.\n",
       "- Advanced media synthesis continues to push boundaries, whether through improved image editors (Nano Banana 2), multimodal video apps (Sora), or translated AI-generated videos (HeyGen).\n",
       "- Infrastructure providers, such as Qualcomm, are now building specialized hardware to meet generative AI's growing compute demands.\n",
       "\n",
       "Let me know if you'd like a detailed breakdown of any of these developments‚Äîfor instance, diving into how Aardvark benchmarks, Gemini 3 Pro‚Äôs likely capabilities, or Sora‚Äôs adoption trends."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive and up-to-date overview of the **latest developments in generative AI** as of November 10, 2025. This analysis draws on recent news, model releases, market trends, and emerging applications.\n",
       "\n",
       "---\n",
       "\n",
       "##  Major Model Releases and Innovations\n",
       "\n",
       "- **OpenAI GPT‚Äë5**  \n",
       "  Released on **August 7, 2025**, GPT‚Äë5 is a multimodal foundation model that integrates reasoning and non-reasoning capabilities under a unified interface. It is accessible via ChatGPT, Microsoft Copilot, and the OpenAI API, and represents a significant leap in performance across benchmarks. ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- **OpenAI o4‚Äëmini**  \n",
       "  Launched on **April 16, 2025**, this lightweight multimodal model supports both text and image inputs, including advanced features like whiteboard sketch analysis and chain-of-thought reasoning. A higher-accuracy variant, o4‚Äëmini‚Äëhigh, is available to paid-tier users. ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai))\n",
       "\n",
       "- **OpenAI GPT‚Äë4.1**  \n",
       "  Released on **April 14, 2025**, GPT‚Äë4.1 (along with mini and nano variants) offers improved coding capabilities and is available to ChatGPT Plus and Pro subscribers. ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-4.1?utm_source=openai))\n",
       "\n",
       "- **Google DeepMind‚Äôs Gemini 2.5 and ‚ÄúNano Banana‚Äù**  \n",
       "  Google‚Äôs Gemini 2.5 Pro and Flash models, featuring enhanced reasoning, coding, and ‚ÄúDeep Think‚Äù capabilities, became generally available on **June 17, 2025**. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai))  \n",
       "  The image-focused variant, **Nano Banana** (Gemini 2.5 Flash Image), launched on **August 26, 2025**, and quickly went viral for its photorealistic 3D figurine-style image generation. It supports features like multi-image fusion, subject consistency, and SynthID watermarking. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))\n",
       "\n",
       "- **Google Gemini Diffusion**  \n",
       "  An experimental model that applies diffusion techniques to text generation, enabling simultaneous generation of text segments with mid-process error correction. It achieves speeds up to **1,479 tokens per second**, significantly faster than Gemini 2.5 Flash (~400 tps) and GPT‚Äë4o (~150 tps). ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai))\n",
       "\n",
       "- **Alibaba Qwen3**  \n",
       "  Released in **April 2025**, this open-source model family includes dense and Mixture-of-Experts variants (up to 235B parameters). It supports ‚Äúthinking‚Äù and ‚Äúnon-thinking‚Äù modes and performs strongly on coding, math, and instruction-following benchmarks. ([spglobal.com](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-digest-a-wave-of-notable-ai-model-launches?utm_source=openai))\n",
       "\n",
       "- **Anthropic Claude Haiku 4.5**  \n",
       "  A compact model launched in **October 2025**, delivering flagship-level reasoning and coding performance at 4‚Äì5√ó the speed and roughly one-third the cost of larger models. It features a 200K token context window and agentic capabilities like process identification. ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai))\n",
       "\n",
       "- **OpenAI Sora (Video App)**  \n",
       "  The Android version of Sora launched on **November 6, 2025**, achieving nearly **470,000 downloads on its first day**, outperforming its iOS debut by 327%. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Emerging Applications & Ecosystem Integration\n",
       "\n",
       "- **TIME AI Agent**  \n",
       "  Launched **today**, this platform integrates language understanding, voice synthesis, translation, and search to deliver interactive, personalized journalism. Developed with Scale AI, it emphasizes editorial accuracy and transparency. ([time.com](https://time.com/7332572/the-story-behind-the-time-ai-agent/?utm_source=openai))\n",
       "\n",
       "- **Google DS STAR**  \n",
       "  Introduced in early November 2025, DS STAR is a multi-agent framework that converts ambiguous business problems into executable Python code, handling mixed-format data (CSV, JSON, Markdown, unstructured text) autonomously. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **Meta Vibes Expansion**  \n",
       "  Meta‚Äôs AI-generated short video platform, Vibes, expanded to Europe in early November 2025, offering TikTok-like experiences where every video is AI-generated. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **Google Maps + Gemini Integration**  \n",
       "  Google Maps is rolling out Gemini-powered voice assistance for intuitive location searches, with global availability expected in the coming weeks. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **HeyGen AI Video Translator**  \n",
       "  Launched in early November 2025, this tool enables hyper-realistic localization of videos, matching tone, expressions, and lip movements. Available via web, iOS, and API with free trial credits. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **ClickUp 4.0**  \n",
       "  Released in early November 2025, this update introduces AI agents and a redesigned UI, integrating task management, collaboration, messaging, scheduling, and enterprise search into a unified platform. ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Market Trends & Strategic Insights\n",
       "\n",
       "- **Generative AI Market Growth**  \n",
       "  A 2025 market report estimates triple-digit growth across GenAI hardware, foundation models, and development platforms in 2024, with over **US$400 billion** in expected AI-related spending in 2025. ([businesswire.com](https://www.businesswire.com/news/home/20250825682581/en/Generative-AI-Market-Report-2025-GenAI-Market-Experienced-Triple-digit-growth-Rates-in-All-Three-Major-Segments-Spanning-GenAI-Hardware-Foundation-Models-and-Development-Platforms---ResearchAndMarkets.com?utm_source=openai))\n",
       "\n",
       "- **Enterprise Adoption & Scaling**  \n",
       "  The latest McKinsey Global Survey (published 5 days ago) shows that while many organizations are still piloting AI, **23%** are scaling agentic AI systems, and **39%** are experimenting with them. High performers are more likely to redesign workflows, define human validation processes, and allocate over **20% of digital budgets** to AI. ([mckinsey.com](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai?utm_source=openai))\n",
       "\n",
       "- **Responsible AI Practices**  \n",
       "  UC Berkeley‚Äôs Responsible Use of Generative AI playbook (June 2025) outlines 10 actionable strategies‚Äîfive for business leaders and five for product managers‚Äîto ensure ethical and responsible GenAI deployment. ([weforum.org](https://www.weforum.org/stories/2025/06/responsible-generative-ai-product-development-use/?utm_source=openai))\n",
       "\n",
       "- **Productivity Study**  \n",
       "  A randomized controlled trial published in July 2025 found that experienced open-source developers using early-2025 AI tools took **19% longer** to complete tasks, suggesting that AI may introduce friction in certain workflows. ([metr.org](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary: What‚Äôs Driving the Generative AI Landscape?\n",
       "\n",
       "1. **Model Evolution**: The field is advancing rapidly with powerful multimodal models like GPT‚Äë5, Gemini 2.5, and Claude Haiku 4.5, alongside experimental innovations like Gemini Diffusion and open-source Qwen3.\n",
       "\n",
       "2. **Application Integration**: Generative AI is increasingly embedded into everyday tools‚Äîfrom journalism (TIME AI Agent) to navigation (Google Maps), video creation (Sora, HeyGen), and productivity platforms (ClickUp).\n",
       "\n",
       "3. **Enterprise Momentum**: Organizations are moving beyond pilots, scaling agentic AI, and investing heavily in AI infrastructure and governance.\n",
       "\n",
       "4. **Ethics & Productivity**: Responsible AI frameworks are gaining prominence, even as studies highlight potential productivity trade-offs in developer workflows.\n",
       "\n",
       "---\n",
       "\n",
       "If you'd like to explore any of these developments in more detail‚Äîsuch as technical capabilities of specific models, enterprise adoption strategies, or ethical frameworks‚Äîjust let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9eedf50-48f8-4092-bb20-c150f3848671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_691263b181a08191900c258ec6e4a346\n",
      "file-VzsW7VcaVGSsejo4A1aMTa\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)\n",
    "\n",
    "with open('my_notes.txt', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive and up-to-date overview of the **latest developments in generative AI** as of November 10, 2025. This analysis draws on recent news, academic findings, and industry releases to highlight key trends and breakthroughs.\n",
       "\n",
       "---\n",
       "\n",
       "##  Major Model Releases and Enhancements\n",
       "\n",
       "- **OpenAI GPT‚Äë5**  \n",
       "  Released on **August 7, 2025**, GPT‚Äë5 is a multimodal foundation model accessible via ChatGPT, Microsoft Copilot, and the OpenAI API. It integrates reasoning and non-reasoning capabilities under a unified interface and achieved state-of-the-art performance across benchmarks at launch ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai)).\n",
       "\n",
       "- **OpenAI o4‚Äëmini**  \n",
       "  Launched on **April 16, 2025**, this lightweight reasoning model supports both text and image inputs, including whiteboard sketch analysis during chain-of-thought reasoning. A higher-accuracy variant, o4‚Äëmini‚Äëhigh, is available to paid users ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai)).\n",
       "\n",
       "- **OpenAI GPT‚Äë4.1**  \n",
       "  Released on **April 14, 2025**, GPT‚Äë4.1 (along with mini and nano variants) offers improved coding capabilities and is available via API and ChatGPT Plus/Pro ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-4.1?utm_source=openai)).\n",
       "\n",
       "- **Anthropic Claude 3.7 Sonnet**  \n",
       "  Introduced in **February 2025**, this hybrid reasoning model features an ‚Äúextended thinking mode‚Äù that enables self-reflection before responding, enhancing performance in math, physics, coding, and more. It‚Äôs available across all Claude plans, with the extended mode on paid tiers ([reuters.com](https://www.reuters.com/technology/artificial-intelligence/anthropic-launches-advanced-ai-hybrid-reasoning-model-2025-02-24/?utm_source=openai)).\n",
       "\n",
       "- **OpenAI gpt‚Äëoss‚Äë120b and gpt‚Äëoss‚Äë20b**  \n",
       "  Released in **August 2025**, these are OpenAI‚Äôs first open-weight models since GPT‚Äë2. The 20B model can run locally on consumer hardware (e.g., PCs with 16GB RAM or Snapdragon processors), while the 120B model requires more powerful GPUs ([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-launches-two-gpt-models-theyre-not-gpt-5-but-they-run-locally-on-snapdragon-pcs-and-nvidia-rtx-gpus?utm_source=openai)). AWS has since made these models available via Bedrock and SageMaker, offering significant cost-efficiency compared to other models ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/amazon-announces-first-ever-availability-of-openai-models-for-its-cloud-customers-company-says-the-addition-of-/articleshow/123125170.cms?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Google DeepMind and Gemini Ecosystem\n",
       "\n",
       "- **Gemini 2.5 Series**  \n",
       "  Google‚Äôs Gemini 2.5 Pro and Flash models, released in early 2025, introduced advanced reasoning, coding capabilities, and a ‚ÄúDeep Think‚Äù mode. Gemini 2.5 Flash became the default model, with Flash‚ÄëLite optimized for speed and cost-efficiency ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gemini_%28language_model%29?utm_source=openai)).\n",
       "\n",
       "- **Nano Banana (Gemini 2.5 Flash Image)**  \n",
       "  Launched on **August 26, 2025**, this image generation and editing model went viral for its photorealistic ‚Äú3D figurine‚Äù outputs. It supports features like subject consistency, multi-image fusion, and SynthID watermarking, and quickly amassed over 10 million new users and 200 million image edits ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Multimedia and Agentic AI Innovations\n",
       "\n",
       "- **Unified Multimedia Models**  \n",
       "  2025 saw a surge in models capable of handling text, image, audio, and video seamlessly:\n",
       "  - **Google Veo 3** (June 2025): Generates video with synchronized sound effects and dialogue ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "  - **OpenAI Sora** (May 2025): Integrated into ChatGPT for conversational video generation ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "  - **Midjourney V7** (May 2025): Introduced 3D model generation and text-to-video tools ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "  - **Runway Gen‚Äë4** (April 2025): Added ‚ÄúCharacter Lock‚Äù to maintain character consistency across video scenes ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai)).\n",
       "\n",
       "- **Agentic AI Tools**  \n",
       "  - **Perplexity Comet**: Launched as the first agentic browser, capable of browsing tabs, voice commands, and task automation. Initially available to Perplexity Max users ([linkedin.com](https://www.linkedin.com/pulse/top-generative-ai-updates-week-july-2-2025-kalyan-ks-oorrc?utm_source=openai)).\n",
       "  - **xAI Grok 4**: Released mid-2025 with a 256K context window and state-of-the-art benchmark performance. Integrated into platforms like Cursor and LangChain ([linkedin.com](https://www.linkedin.com/pulse/top-generative-ai-updates-week-july-2-2025-kalyan-ks-oorrc?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Hardware and Infrastructure Advances\n",
       "\n",
       "- **Qualcomm AI200 and AI250 Accelerators**  \n",
       "  Announced in **October 2025**, these upcoming AI inference accelerators target data center workloads with features like micro-tile inferencing, 64-bit addressing, and Gen AI model encryption. The AI200 is slated for 2026 release, with AI250 following in 2027 ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Academic and Research Highlights\n",
       "\n",
       "- **Diffusion Models in Protein Design**  \n",
       "  A 2025 study highlights the success of diffusion-based generative models (e.g., RFDiffusion) in de novo protein design, outperforming traditional methods and reducing experimental costs ([arxiv.org](https://arxiv.org/abs/2504.16479?utm_source=openai)).\n",
       "\n",
       "- **Semantic Information Theory for Multimedia AI**  \n",
       "  A recent paper (August 2025) proposes a semantic-first information-theoretic framework for generative AI in multimedia communication, introducing concepts like semantic entropy and channel capacity ([arxiv.org](https://arxiv.org/abs/2508.17163?utm_source=openai)).\n",
       "\n",
       "- **Quantum Generative Advantage**  \n",
       "  A September 2025 study demonstrates generative quantum models on a 68-qubit superconducting processor, achieving tasks beyond classical simulation capabilities and marking a milestone in quantum-enhanced generative AI ([arxiv.org](https://arxiv.org/abs/2509.09033?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Summary of Key Trends\n",
       "\n",
       "- **Multimodal Integration**: Models now seamlessly handle text, image, audio, and video.\n",
       "- **Reasoning and Reflection**: Features like ‚Äúthinking modes‚Äù and self-reflection are becoming standard.\n",
       "- **Accessibility and Efficiency**: Open-weight models and hardware optimizations are democratizing AI.\n",
       "- **Agentic Capabilities**: AI is evolving from reactive tools to autonomous agents.\n",
       "- **Cross-Domain Impact**: Generative AI is advancing in fields like protein design and quantum computing.\n",
       "\n",
       "---\n",
       "\n",
       "If you'd like to explore any of these developments in more detail‚Äîsuch as GPT‚Äë5‚Äôs architecture, Nano Banana‚Äôs technical underpinnings, or the implications of quantum generative models‚Äîjust let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf60b0b-5dbf-4b4f-8c7e-7b7573ea4e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
